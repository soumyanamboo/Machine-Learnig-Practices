{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAnIVZfOMiMr24VU2DyFIT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twj4gWtY-VJL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import explained_variance_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practice Assignment\n",
        "Q1 Write the function compute_explained_variance(y_true, y_pred) for calculating the explained variance score for a linear regression dataset Here y_true is the true (actual) label and y_pred is the predicted label. The function should return the explained variance scoreevs. Consider, y_true = [7, 4, 9, 4] and y_pred = [8, 7, 12, 5] For these labels, what is the output of the function 'compute_explained_variance'? (Enter your answer in four decimal places)"
      ],
      "metadata": {
        "id": "BozJkZwG-Xz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_explained_variance(y_true, y_pred):\n",
        "  return explained_variance_score(y_true=y_true, y_pred=y_pred)\n",
        "\n",
        "y_true = [7, 4, 9, 4]\n",
        "y_pred = [8, 7, 12, 5]\n",
        "print(compute_explained_variance(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxHXYbqF-u70",
        "outputId": "a0684567-4acd-497d-a2ed-88b7d46f227e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Write a function compute_score(X_train, y_train, X_test, y_test) to compute the score of SGDRegressor for predicting the house price of California Housing dataset.   \n",
        "Write your code based on the following keypoints:\n",
        "\n",
        "* Split the California housing dataset into train and test set with 70:30 ratio and random_state = 1\n",
        "* Import StandardScaler for scaling X_train and X_test to X_train_norm and X_test_norm with_mean = True and with_std = True \n",
        "\n",
        "* Import SGDRegressor as 'model' with hyperparamters \n",
        "loss as 'squared_error', penalty as 'l1' and alpha as 0.01 and random_state = 1\n",
        "\n",
        "* Train the 'model' and compute the 'score' on test data\n",
        "Enter the value of the 'score' computed from the function 'compute_score'. (Enter your answer in four decimal places)"
      ],
      "metadata": {
        "id": "7xsJpQ1Z_1YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "#print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "I-9nXyN2_4aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(X_train, y_train, X_test, y_test):\n",
        "  sc = StandardScaler(with_mean=True, with_std=True)\n",
        "  X_train_norm = sc.fit_transform(X_train)\n",
        "  X_test_norm = sc.transform(X_test)\n",
        "\n",
        "  model = SGDRegressor(loss='squared_error', penalty='l1', alpha=0.01, random_state=1)\n",
        "  model.fit(X_train_norm, y_train)\n",
        "\n",
        "  score = model.score(X_test_norm, y_test)\n",
        "  return score"
      ],
      "metadata": {
        "id": "JGCAYZMwJxxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = compute_score(X_train, y_train, X_test, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvT-5H8mKUmg",
        "outputId": "89dc8e76-cd90-4d3a-a630-6b7d6584d2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5951040704728554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Graded Assignment\n",
        "\n",
        "Q1) Write a function k_fold_cv(X) to run 2-fold cross validation repeated 2 times for the array X = [[1, 2], [3, 4], [1, 2], [3, 4]] which will return a concatenated array combining the training and testing dataset. Set random_state=1 in your code. Which of the following options denote the concatenated array?"
      ],
      "metadata": {
        "id": "mRnq-ZIcONvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "def k_fold_cv(X):\n",
        "  concat_array = []\n",
        "  result = RepeatedKFold(n_splits=2, n_repeats=2, random_state=1)\n",
        "  split=1\n",
        "  for train, test in result.split(X):\n",
        "    #print(train, test)\n",
        "    split += 1\n",
        "  concat_array = np.append(train, test)\n",
        "\n",
        "  return concat_array"
      ],
      "metadata": {
        "id": "qeEuj8nqOarO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [[1, 2], [3, 4], [1, 2], [3, 4]]\n",
        "print(k_fold_cv(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV5bwokNOggz",
        "outputId": "d39cbe68-3a96-4ac4-d280-fb58ed9d5e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a code to predict the house price of California Housing dataset using GridSearchCV.\n",
        "\n",
        "Write your code based on the following keypoints:\n",
        "\n",
        "* Split the California housing dataset into train and test set with 70:30 ratio with random_state = 1\n",
        "* Import StandardScaler for scaling X_train and X_test to X_train_norm and X_test_norm with_mean = True and with_std = True\n",
        "* Import SGDRegressor with random_state = 1\n",
        "* Pass SGDRegressor through GridSearchCV Hyperparamter tuning to be done over loss as 'squared_error' or 'huber' penalty as 'l1' or 'l2' alpha  as 0.1, 0.01, 0.001 maximum number of passes as [1000,2000,5000]\n",
        "* Cross Validation = 4\n",
        "* Train the 'model' and compute the 'score' on test data"
      ],
      "metadata": {
        "id": "9piqthTqQZLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) Enter the value of the 'score'.(Enter your answer in four decimal places)"
      ],
      "metadata": {
        "id": "N9i_fiJqQ572"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "0AtmSh_XSbaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "sc = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_norm = sc.fit_transform(X_train)\n",
        "X_test_norm = sc.transform(X_test)\n",
        "\n",
        "sgd_reg = SGDRegressor(random_state=1)\n",
        "param_grid = {\"loss\": ['squared_error', 'huber'],\n",
        "             'penalty': ['l1', 'l2'],\n",
        "             'alpha':[0.1, 0.01, 0.001],\n",
        "             'max_iter': [1000,2000,5000]\n",
        "             }\n",
        "sgd_reg_search = GridSearchCV(sgd_reg,\n",
        "                              param_grid=param_grid,\n",
        "                              cv=4,\n",
        "                              return_train_score=True\n",
        "                              )\n",
        "sgd_reg_search.fit(X_train_norm, y_train)\n",
        "score = sgd_reg_search.score(X_test_norm, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj2-e5tvQ4Fp",
        "outputId": "84b2e099-05f7-47a8-f3d2-341bb840629f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5951040704728554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3, 4"
      ],
      "metadata": {
        "id": "04PpTCjEUR8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_reg_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bu_CNi9UHjG",
        "outputId": "ee08ebc6-c937-490e-bc29-3064e43bd59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.01, 'loss': 'squared_error', 'max_iter': 1000, 'penalty': 'l1'}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a code to predict the house price of California Housing dataset using GridSearchCV.  \n",
        "Write your code based on the following keypoints:\n",
        "\n",
        "* Split the California housing dataset into train and test set with 70:30 ratio with random_state = 1\n",
        "* Import StandardScaler for scaling X_train and X_test to X_train_norm and X_test_norm with_mean = True and with_std = True\n",
        "* Pass Ridge Regression Model through GridSearchCV\n",
        "* Hyperparamter tuning to be done over\n",
        "  * alpha as 0.5,0.1,0.05,0.01,0.005,0.001\n",
        "  * With or without intercept\n",
        "  * Cross Validation = 4\n",
        "\n",
        "Train the 'model' and compute the 'score' on test data\n",
        "\n",
        "Q 5, 6"
      ],
      "metadata": {
        "id": "URfd8eGuUgm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "sc = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_norm = sc.fit_transform(X_train)\n",
        "X_test_norm = sc.transform(X_test)\n",
        "\n",
        "ridge = Ridge()\n",
        "param_grid = {'alpha':[0.5,0.1,0.05,0.01,0.005,0.001],\n",
        "             'fit_intercept': [True, False]\n",
        "             }\n",
        "ridge_search = GridSearchCV(ridge,\n",
        "                              param_grid=param_grid,\n",
        "                              cv=4,\n",
        "                              return_train_score=True\n",
        "                              )\n",
        "ridge_search.fit(X_train_norm, y_train)\n",
        "score = ridge_search.score(X_test_norm, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVdFkximU0zH",
        "outputId": "e339597b-2bae-47c8-cec3-134c146a0b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.597145061224877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGmRlMC1V64g",
        "outputId": "7479d484-fdd8-441d-8580-c93abfccc9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.5, 'fit_intercept': True}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a code to predict the house price of California Housing dataset using GridSearchCV.\n",
        "\n",
        "Write your code based on the following keypoints:\n",
        "* Split the California housing dataset into train and test set with 60:40 ratio with random_state = 1\n",
        "* Import StandardScaler for scaling X_train and X_test to X_train_norm and X_test_norm with_mean = True and with_std = True\n",
        "* Pass Lasso Model through GridSearchCV\n",
        "* Hyperparamter tuning to be done over\n",
        "    * alpha as 0.5,0.1,0.05,0.01,0.005,0.001\n",
        "    * With or without intercept\n",
        "    * Cross Validation = 6\n",
        "\n",
        "Train the 'model' and compute the 'score' on test data\n",
        "\n",
        "Q 7, 8"
      ],
      "metadata": {
        "id": "w4CESNqOWGRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "sc = StandardScaler(with_mean=True, with_std=True)\n",
        "X_train_norm = sc.fit_transform(X_train)\n",
        "X_test_norm = sc.transform(X_test)\n",
        "\n",
        "lasso = Lasso()\n",
        "param_grid = {'alpha':[0.5,0.1,0.05,0.01,0.005,0.001],\n",
        "             'fit_intercept': [True, False]\n",
        "             }\n",
        "lasso_search = GridSearchCV(ridge,\n",
        "                              param_grid=param_grid,\n",
        "                              cv=6,\n",
        "                              return_train_score=True\n",
        "                              )\n",
        "lasso_search.fit(X_train_norm, y_train)\n",
        "score = lasso_search.score(X_test_norm, y_test)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmiwtaX8We75",
        "outputId": "892dc49b-f887-4a5f-f766-d07b20f86f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6068352731003703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_search.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-DpICM5W5u6",
        "outputId": "65954b78-d09f-4472-d509-672f575f133e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.5, 'fit_intercept': True}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lGwowGxdXC89"
      }
    }
  ]
}